# RAG_LLM
LLM using rag method with Ollama model and langchain community then display with a web localhost:8501
